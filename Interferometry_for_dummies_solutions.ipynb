{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982a90bb",
   "metadata": {},
   "source": [
    "## Interferometry for dummies notebook\n",
    "\n",
    "This notebook should take you through some of the concepts that have been discussed in the lecture. Therefore, clues to all the solutions should be present in the slides. The purpose here is to get some hands-on experience, not to get hung up on coding issues. If you are stuck, there is an equivalent notebook containing the solutions from which you can draw inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135db84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "from astropy.io import ascii, fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e59981",
   "metadata": {},
   "source": [
    "### Fourier transforms in 1D\n",
    "\n",
    "To get a feel for the fast Fourier transform functionality in numpy, see if you can get the primary beam pattern of single dish, assuming the aperture is uniformly illuminated.\n",
    "\n",
    "As the Fourier transform is discrete and finite, the resulting function will not be perfect. Check to see how the size of the aperture relative to the sampled space and the sampling interval influence the result.\n",
    "\n",
    "**If your results are strange or unexpected**: Whereas we like our signals to be in the middle of the sampled space for aesthetic reasons, the discrete Fourier transform follows the python indexing, which means that the 0-point will be right at the edges of the array. In general, `np.fft.fftshift` is your best friend here, and it is best to use it before and after every Fourier transform. Trust me, this will save you a lot of trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define amount of samples and extent of parameter space\n",
    "nsamples=1024\n",
    "X=100\n",
    "\n",
    "x = np.linspace(-X/2,X/2,nsamples)\n",
    "y = np.zeros(nsamples)\n",
    "\n",
    "# Make tophat\n",
    "y[np.logical_and(x>-0.5,x<0.5)] = 1\n",
    "plt.plot(x,y)\n",
    "plt.show()\n",
    "\n",
    "# Fourier transform\n",
    "y_fft = np.fft.fftshift(np.fft.fft(np.fft.fftshift(y)))\n",
    "plt.plot(x, np.real(y_fft)*(X/nsamples))\n",
    "plt.plot(x, np.sinc(x*(X/nsamples)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e4787",
   "metadata": {},
   "source": [
    "### Simulating MeerKAT observations\n",
    "\n",
    "In the data subdirectory, a text file is included with the UV-coverage of a MeerKAT observation. \n",
    "\n",
    "1. Start with plotting the UV-coverage, preferably in units of $k\\lambda$, assuming $\\lambda=$21 cm.\n",
    "\n",
    "2. Using 2D Fourier transforms, convert the UV-coverage to a Point-spread-function (PSF). To do this you need to define a grid for UV space first, which will define the resolution and size of your resulting image. **Bonus**: Implement both natural and uniform weighting schemes, and see how this influences the shape of the PSF. \n",
    "\n",
    "3. In the data subdirectory there is a fits file containing the sky emission from a FRII radio galaxy. Using the data just obtained, convolve this image with PSF using 2D Fourier transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b225340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in MeerKAT UV-coverage\n",
    "meerkat_uv = ascii.read('data/meerkat_uv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UV plane, and remember that each baseline has its conjugate!\n",
    "plt.scatter(meerkat_uv['u']/0.21/1000,meerkat_uv['v']/0.21/1000, color='k', s=1)\n",
    "plt.scatter(-meerkat_uv['u']/0.21/1000,-meerkat_uv['v']/0.21/1000, color='k', s=1)\n",
    "plt.xlabel('u (k$\\lambda$)')\n",
    "plt.ylabel('v (k$\\lambda$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uv_points_to_psf(u, v, imsize, weighting):\n",
    "    '''\n",
    "    Grid and Fourier transform UV coverage to create a PSF\n",
    "    '''\n",
    "    uv_image = np.zeros(shape=(imsize,imsize))\n",
    "\n",
    "    if weighting == 'natural':\n",
    "        for i in range(len(u)):\n",
    "            uv_image[int(u[i]),int(v[i])] += 1\n",
    "    if weighting == 'uniform':\n",
    "        for i in range(len(u)):\n",
    "            uv_image[int(u[i]),int(v[i])] = 1\n",
    "\n",
    "    psf = np.fft.fftshift(np.fft.fft2(uv_image))\n",
    "\n",
    "    return uv_image, psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cc78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gridded UV coverage and PSF\n",
    "uv_image, psf = uv_points_to_psf(meerkat_uv['u']/10, meerkat_uv['v']/10, imsize=4096, weighting='uniform')\n",
    "\n",
    "plt.imshow(psf.real, cmap='YlGnBu_r', origin='lower')\n",
    "plt.xlim(1948,2148)\n",
    "plt.ylim(1948,2148)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in radio galaxy fits file\n",
    "radio_galaxy = fits.open('data/radio_galaxy.fits')[0].data\n",
    "\n",
    "plt.imshow(radio_galaxy, cmap='YlGnBu_r')\n",
    "plt.xlim(1548,2548)\n",
    "plt.ylim(1548,2548)\n",
    "plt.show()\n",
    "\n",
    "# Convolve image with MeerKAT PSF\n",
    "radio_sources_vis = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(radio_galaxy)))\n",
    "convolved_vis = radio_sources_vis*np.fft.fftshift(uv_image)\n",
    "convolved = np.fft.fftshift(np.fft.ifft2(np.fft.fftshift(convolved_vis)))\n",
    "\n",
    "plt.imshow(convolved.real, cmap='YlGnBu_r')\n",
    "plt.xlim(1548,2548)\n",
    "plt.ylim(1548,2548)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e22fd",
   "metadata": {},
   "source": [
    "### Implementing CLEAN\n",
    "\n",
    "In the data subdirectory you will find a dirty image containing a number of point sources. In the same directory an image of the PSF is included. \n",
    "\n",
    "To clean the image, implement the HÃ¶gbom CLEAN algorithm as specified in the slides, including a gain factor, an iteration limit, and a noise treshold. To create the clean image, the 2D Gaussian fit to the central lobe of the beam is 7.8x5.6 pixels with PA of 75, I have already defined as an astropy kernel. I have also included a function which takes care of subtracting two images which are shifted w.r.t. each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion factor from FWHM to std\n",
    "a = 2*np.sqrt(2*np.log(2))\n",
    "\n",
    "maj_std = 7.8/a\n",
    "min_std = 5.6/a\n",
    "theta = np.deg2rad(75)\n",
    "\n",
    "# Define clean beam\n",
    "clean_beam = Gaussian2DKernel(x_stddev = min_std,\n",
    "                              y_stddev = maj_std,\n",
    "                              theta=theta,\n",
    "                              x_size=51, y_size=51)\n",
    "# Normalize the beam\n",
    "clean_beam_normed = clean_beam.array/clean_beam.array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_shifted_images(im1, im2, X, Y, amp):\n",
    "    '''\n",
    "    Subtract amp*im2 from im1, given an offset in X and Y\n",
    "    '''\n",
    "    im1_xshape = int(im1.shape[0]/2)\n",
    "    im1_yshape = int(im1.shape[1]/2)\n",
    "        \n",
    "    im2_xshape = int(im2.shape[0])\n",
    "    im2_yshape = int(im2.shape[1])\n",
    "    \n",
    "    minY = min(int(Y)-im1_yshape, 0)\n",
    "    minX = min(int(X)-im1_xshape, 0)\n",
    "    maxY = max(int(Y)+im1_yshape-im2_yshape, 0)\n",
    "    maxX = max(int(X)+im1_xshape-im2_xshape, 0)\n",
    "\n",
    "    im1[int(X)-im1_xshape-minX:int(X)+im1_xshape-maxX,\n",
    "        int(Y)-im1_yshape-minY:int(Y)+im1_yshape-maxY] -= amp*im2[-minX:im2_xshape-maxX,-minY:im2_yshape-maxY]\n",
    "    \n",
    "    return im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e83934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogbom_clean(dirty_image, psf, gain, niter, thresh):\n",
    "    '''\n",
    "    Implement Hogbom clean with gain, niter and threshold\n",
    "    '''\n",
    "    model_image=np.zeros(dirty_image.shape)\n",
    "    residual=copy(dirty_image)\n",
    "    \n",
    "    for i in range(niter):\n",
    "        x, y = np.unravel_index(residual.argmax(), residual.shape)\n",
    "        print(x,y,residual[x,y])\n",
    "        \n",
    "        amp = gain*residual[x,y]\n",
    "        \n",
    "        model_image[x,y] += amp\n",
    "        residual = subtract_shifted_images(residual, psf, x, y, amp)\n",
    "        \n",
    "        if residual.max() < thresh:\n",
    "            print(i)\n",
    "            break\n",
    "\n",
    "    return model_image, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e31886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in dirty image and PSF\n",
    "dirty_image = fits.open('data/dirty_image.fits')\n",
    "psf = fits.open('data/psf.fits')\n",
    "\n",
    "# Run CLEAN\n",
    "model_image, residual = hogbom_clean(dirty_image[0].data, psf[0].data, gain=0.1, niter=1000, thresh=5e-2)\n",
    "# Create CLEAN image\n",
    "clean_image = convolve(model_image, clean_beam_normed, normalize_kernel=False, nan_treatment='fill') + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write model image to fits\n",
    "hdu = fits.PrimaryHDU(model_image, header=dirty_image[0].header)\n",
    "hdu.writeto('data/model_image.fits', overwrite=True)\n",
    "\n",
    "#Write CLEAN image to fits\n",
    "hdu = fits.PrimaryHDU(clean_image, header=dirty_image[0].header)\n",
    "hdu.writeto('data/clean_image.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e69840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
